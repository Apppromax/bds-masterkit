import { supabase } from '../lib/supabaseClient';

async function saveApiLog(data: {
    provider: string;
    model: string;
    endpoint: string;
    status_code: number;
    duration_ms: number;
    prompt_preview: string;
}) {
    try {
        const { data: { session } } = await supabase.auth.getSession();
        if (!session?.user) return;

        const { error } = await supabase.from('api_logs').insert({
            user_id: session.user.id,
            ...data
        });

        if (error) {
            console.warn('[Log] RLS/Database error:', error.message);
        } else {
            console.log('[Log] API usage tracked successfully');
        }
    } catch (err) {
        console.error('[Log] Failed to save API log:', err);
    }
}

async function getApiKey(provider: string): Promise<string | null> {
    try {
        console.log(`[AI] Fetching best key for: ${provider}`);
        const { data, error } = await supabase.rpc('get_best_api_key', { p_provider: provider });

        if (error) {
            console.error(`[AI] RPC Error (${provider}):`, error.message, error.details);
            // If it's a transient session issue, a quick retry might help
            if (error.message.includes('JWT') || error.message.includes('session')) {
                console.log(`[AI] Retrying ${provider} after potential auth race...`);
                const retry = await supabase.rpc('get_best_api_key', { p_provider: provider });
                if (retry.data) return retry.data;
            }
            return null;
        }

        if (!data) {
            console.warn(`[AI] No active key found in pool for: ${provider}. Retrying once...`);
            // Quick retry for cold start
            await new Promise(r => setTimeout(r, 800));
            const retry = await supabase.rpc('get_best_api_key', { p_provider: provider });
            if (retry.data) {
                console.log(`[AI] Retry successful for ${provider}`);
                return retry.data;
            }

            console.error(`[AI] Final check: No keys for ${provider}`);
            return null;
        }

        return data;
    } catch (err) {
        console.error(`[AI] Fatal error fetching key (${provider}):`, err);
        return null;
    }
}

export async function generateContentWithAI(
    prompt: string,
    options?: { channel?: string, audience?: string, style?: string, multiOption?: boolean, name?: string, phone?: string }
): Promise<string | null> {
    const startTime = Date.now();

    const styleGuide: Record<string, string> = {
        professional: 'Phong c√°ch chuy√™n nghi·ªáp, trang tr·ªçng, ng√¥n t·ª´ chu·∫©n m·ª±c, ƒë·∫ßy ƒë·ªß th√¥ng tin k·ªπ thu·∫≠t.',
        urgent: 'Phong c√°ch kh·∫©n c·∫•p, h·ªëi th√∫c, s·ª≠ d·ª•ng c√°c t·ª´ m·∫°nh nh∆∞ "C·∫Øt l·ªó", "B√°n g·∫•p", "Ch·ªët ngay", "C∆° h·ªôi duy nh·∫•t".',
        funny: 'Phong c√°ch h√†i h∆∞·ªõc, d√≠ d·ªèm, s·ª≠ d·ª•ng c√°c c√¢u v√≠ von th√∫ v·ªã, c√°c trend m·∫°ng x√£ h·ªôi n·∫øu ph√π h·ª£p.',
        sincere: 'Phong c√°ch ch√¢n th√†nh, t√¢m huy·∫øt, chia s·∫ª th·∫≠t l√≤ng v·ªÅ gi√° tr·ªã c·ªßa BƒêS.',
        story: 'Phong c√°ch k·ªÉ chuy·ªán (storytelling), d·∫´n d·∫Øt ng∆∞·ªùi ƒë·ªçc v√†o m·ªôt tr·∫£i nghi·ªám s·ªëng ho·∫∑c ƒë·∫ßu t∆∞ th·ª±c t·∫ø.'
    };

    // Build specialized system instructions
    const systemPrompt = `B·∫°n l√† m·ªôt chuy√™n gia Content Marketing B·∫•t ƒë·ªông s·∫£n cao c·∫•p t·∫°i Vi·ªát Nam. 
Nhi·ªám v·ª•: T·∫°o n·ªôi dung qu·∫£ng c√°o c√≥ t·ª∑ l·ªá chuy·ªÉn ƒë·ªïi cao.
${options?.style ? `Gi·ªçng vƒÉn y√™u c·∫ßu: ${styleGuide[options.style] || options.style}.` : ''}
${options?.channel ? `K√™nh ph√°t h√†nh: ${options.channel.toUpperCase()}. T·ªëi ∆∞u h√≥a ƒë·ªãnh d·∫°ng v√† ng√¥n ng·ªØ cho k√™nh n√†y.` : ''}
${options?.audience === 'investor' ? 'ƒê·ªëi t∆∞·ª£ng m·ª•c ti√™u: Nh√† ƒë·∫ßu t∆∞. T·∫≠p trung v√†o: L·ª£i nhu·∫≠n, ti·ªÅm nƒÉng tƒÉng gi√°, ph√°p l√Ω, v·ªã tr√≠ chi·∫øn l∆∞·ª£c, t√≠nh thanh kho·∫£n.' : ''}
${options?.audience === 'homeseeker' ? 'ƒê·ªëi t∆∞·ª£ng m·ª•c ti√™u: Kh√°ch mua ·ªü. T·∫≠p trung v√†o: Ti·ªán √≠ch, kh√¥ng gian s·ªëng, m√¥i tr∆∞·ªùng xung quanh, c·∫£m x√∫c t·ªï ·∫•m, s·ª± ti·ªán nghi cho gia ƒë√¨nh.' : ''}
Y√™u c·∫ßu: S·ª≠ d·ª•ng Emoji kh√©o l√©o, Headline gi·∫≠t g√¢n, Call-to-Action m·∫°nh m·∫Ω. Chia r√µ c√°c ph·∫ßn b·∫±ng xu·ªëng d√≤ng.
${options?.phone ? `TH√îNG TIN LI√äN H·ªÜ B·∫ÆT BU·ªòC: B·∫°n PH·∫¢I ch√®n d√≤ng "${options.name || 'Admin'} - ${options.phone}" (k√®m icon ƒëi·ªán tho·∫°i ƒë·∫πp m·∫Øt) v√†o cu·ªëi **M·ªñI** ph∆∞∆°ng √°n n·ªôi dung (tr∆∞·ªõc khi sang ph∆∞∆°ng √°n ti·∫øp theo, n·∫øu c√≥ nhi·ªÅu ph∆∞∆°ng √°n).` : ''}`;

    let fullPrompt = `${systemPrompt}\n\nTh√¥ng tin chi ti·∫øt:\n${prompt}`;

    if (options?.multiOption) {
        fullPrompt += `\n\nH√£y t·∫°o 3 ph∆∞∆°ng √°n n·ªôi dung kh√°c nhau. QUAN TR·ªåNG: NgƒÉn c√°ch gi·ªØa c√°c ph∆∞∆°ng √°n b·∫±ng chu·ªói "---SPLIT---". TUY·ªÜT ƒê·ªêI KH√îNG ƒë∆∞·ª£c vi·∫øt c√°c t·ª´ nh∆∞ "Ph∆∞∆°ng √°n 1", "M·∫´u 1", "L·ª±a ch·ªçn 1"... ·ªü ƒë·∫ßu m·ªói n·ªôi dung. H√£y v√†o th·∫≥ng ti√™u ƒë·ªÅ b√†i vi·∫øt lu√¥n.`;
    }

    const maxRetries = 3;
    const retryDelay = 2000; // 2 seconds

    // 1. Try Gemini
    const geminiKey = await getApiKey('gemini');

    if (geminiKey) {
        for (let attempt = 0; attempt <= maxRetries; attempt++) {
            try {
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${geminiKey}`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        contents: [{ parts: [{ text: fullPrompt }] }]
                    })
                });

                if (response.status === 429) {
                    console.warn(`[AI] Gemini 429 Rate Limit (Attempt ${attempt + 1}/${maxRetries + 1}). Retrying in ${retryDelay}ms...`);
                    if (attempt < maxRetries) {
                        await new Promise(r => setTimeout(r, retryDelay));
                        continue;
                    }
                }

                const data = await response.json();
                await saveApiLog({
                    provider: 'gemini',
                    model: 'gemini-2.0-flash',
                    endpoint: 'generateContent',
                    status_code: response.status,
                    duration_ms: Date.now() - startTime,
                    prompt_preview: fullPrompt.substring(0, 100)
                });

                if (data.candidates && data.candidates[0].content) {
                    return data.candidates[0].content.parts[0].text;
                }
                break; // Exit loop if success or non-retryable error
            } catch (err) {
                console.error('Gemini API Error:', err);
                if (attempt < maxRetries) await new Promise(r => setTimeout(r, retryDelay));
            }
        }
    }

    // 2. Fallback to OpenAI
    const openaiKey = await getApiKey('openai');

    if (openaiKey) {
        const ostartTime = Date.now();
        for (let attempt = 0; attempt <= maxRetries; attempt++) {
            try {
                const response = await fetch('https://api.openai.com/v1/chat/completions', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${openaiKey}`
                    },
                    body: JSON.stringify({
                        model: 'gpt-3.5-turbo',
                        messages: [
                            { role: 'system', content: systemPrompt },
                            { role: 'user', content: fullPrompt }
                        ],
                        temperature: 0.8
                    })
                });

                if (response.status === 429) {
                    console.warn(`[AI] OpenAI 429 Rate Limit (Attempt ${attempt + 1}/${maxRetries + 1}). Retrying...`);
                    if (attempt < maxRetries) {
                        await new Promise(r => setTimeout(r, retryDelay));
                        continue;
                    }
                }

                const data = await response.json();
                await saveApiLog({
                    provider: 'openai',
                    model: 'gpt-3.5-turbo',
                    endpoint: 'chat/completions',
                    status_code: response.status,
                    duration_ms: Date.now() - ostartTime,
                    prompt_preview: fullPrompt.substring(0, 100)
                });

                if (data.choices && data.choices[0]?.message?.content) {
                    return data.choices[0].message.content;
                }
                break;
            } catch (err) {
                console.error('OpenAI API Error:', err);
                if (attempt < maxRetries) await new Promise(r => setTimeout(r, retryDelay));
            }
        }
    }

    console.error('Final failure: No usable keys found for Gemini or OpenAI.');
    return null;
}

export async function analyzeImageWithGemini(base64Image: string): Promise<string | null> {
    const geminiKey = await getApiKey('gemini');

    if (!geminiKey) return null;

    // Clean base64 header
    const cleanBase64 = base64Image.replace(/^data:image\/(png|jpeg|webp);base64,/, '');

    const visionPrompt = `B·∫°n l√† CHUY√äN GIA MARKETING B·∫§T ƒê·ªòNG S·∫¢N. Nhi·ªám v·ª•: Nh√¨n b·ª©c ·∫£nh n√†y b·∫±ng con m·∫Øt c·ªßa M√îI GI·ªöI mu·ªën b√°n h√†ng, r·ªìi vi·∫øt prompt ti·∫øng Anh ƒë·ªÉ AI ch·ªânh s·ª≠a ·∫£nh sao cho KH√ÅCH H√ÄNG MU·ªêN MUA.

B∆Ø·ªöC 1 ‚Äî PH√ÇN LO·∫†I (x√°c ƒë·ªãnh scenario):
A) ƒê·∫§T N·ªÄN TR·ªêNG / PH√ÇN L√î: ƒê·∫•t ƒë√£ c·∫Øm c·ªçc, c√≥ ranh gi·ªõi, nh∆∞ng ch∆∞a x√¢y d·ª±ng.
B) NH√Ä TH√î / X√ÇY DANG D·ªû: C√≥ khung s∆∞·ªùn nh∆∞ng ch∆∞a ho√†n thi·ªán.
C) CƒÇN H·ªò / PH√íNG C≈®: N·ªôi th·∫•t c≈© k·ªπ, t·ªëi tƒÉm, ho·∫∑c ph√≤ng tr·ªëng.
D) NH√Ä ƒê√É HO√ÄN THI·ªÜN: C·∫ßn tƒÉng t√≠nh h·∫•p d·∫´n (curb appeal).
E) KH√ÅC: M√¥ t·∫£ ng·∫Øn.

B∆Ø·ªöC 2 ‚Äî X√ÅC ƒê·ªäNH "N·ªñI ƒêAU MARKETING" (kh√¥ng ph·∫£i l·ªói ·∫£nh, m√† l√† l√Ω do kh√°ch h√†ng KH√îNG MU·ªêN MUA khi nh√¨n ·∫£nh n√†y):
V√≠ d·ª• n·ªói ƒëau theo scenario:
- ƒê·∫•t n·ªÅn: "Tr√¥ng hoang vu, kh√¥ng th·∫•y ƒë∆∞·ªùng ƒëi, kh√¥ng c√≥ d·∫•u hi·ªáu ph√°t tri·ªÉn xung quanh, thi·∫øu h·∫° t·∫ßng"
- Nh√† th√¥: "Tr√¥ng nh∆∞ b·ªè hoang, kh√¥ng h√¨nh dung ƒë∆∞·ª£c khi ho√†n thi·ªán s·∫Ω ra sao"
- Ph√≤ng c≈©: "T·ªëi tƒÉm, n·ªôi th·∫•t l·ªói th·ªùi, kh√¥ng gian ch·∫≠t h·∫πp"
- Nh√† ho√†n thi·ªán: "S√¢n tr∆∞·ªõc nh·∫øch nh√°c, thi·∫øu c√¢y xanh, √°nh s√°ng x·∫•u"

B∆Ø·ªöC 3 ‚Äî VI·∫æT PROMPT CH·ªÆA L√ÄNH (ti·∫øng Anh). Quy t·∫Øc theo t·ª´ng scenario:

üèóÔ∏è N·∫æU L√Ä ƒê·∫§T N·ªÄN:
- Gi·ªØ nguy√™n ranh gi·ªõi l√¥ ƒë·∫•t, c·ªçc m·ªëc, b·ªù k√®
- Bi·∫øn ƒë·∫•t tr·ªëng th√†nh th·∫£m c·ªè xanh g·ªçn g√†ng (manicured grass) tr√™n m·ªói l√¥
- Th√™m ƒë∆∞·ªùng n·ªôi b·ªô r√µ r√†ng (paved road) n·∫øu ch∆∞a c√≥ ho·∫∑c ƒë∆∞·ªùng ch∆∞a r√µ
- Th√™m 2-3 ng√¥i nh√† d√¢n nh·ªè ·ªü XA (background, small scale) ƒë·ªÉ t·∫°o c·∫£m gi√°c khu d√¢n c∆∞ ƒëang ph√°t tri·ªÉn
- Th√™m ƒë√®n ƒë∆∞·ªùng (street lights), v·ªâa h√® s·∫°ch
- B·∫ßu tr·ªùi xanh trong, n·∫Øng v√†ng nh·∫π

üèöÔ∏è N·∫æU L√Ä NH√Ä TH√î:
- Gi·ªØ nguy√™n khung s∆∞·ªùn, v·ªã tr√≠ t∆∞·ªùng/c·ªôt
- Th√™m l·ªõp s∆°n/ho√†n thi·ªán b·ªÅ m·∫∑t (painted walls, tiled floor)
- Th√™m c·ª≠a s·ªï k√≠nh, c·ª≠a ch√≠nh
- S√¢n tr∆∞·ªõc c√≥ c·ªè v√† l·ªëi ƒëi

üõãÔ∏è N·∫æU L√Ä CƒÇN H·ªò/PH√íNG:
- Gi·ªØ nguy√™n b·ªë c·ª•c ph√≤ng, v·ªã tr√≠ c·ª≠a/c·ª≠a s·ªï
- Virtual staging: Th√™m n·ªôi th·∫•t hi·ªán ƒë·∫°i ph√π h·ª£p (sofa, b√†n ƒÉn, gi∆∞·ªùng, ƒë√®n)
- TƒÉng √°nh s√°ng t·ª± nhi√™n t·ª´ c·ª≠a s·ªï
- S√†n s·∫°ch, t∆∞·ªùng s∆°n m·ªõi

üè° N·∫æU L√Ä NH√Ä HO√ÄN THI·ªÜN:
- Gi·ªØ nguy√™n ki·∫øn tr√∫c
- C·∫£i thi·ªán s√¢n v∆∞·ªùn (th√™m c√¢y, hoa, l·ªëi ƒëi)
- Golden hour lighting
- B·∫ßu tr·ªùi ƒë·∫πp

QUY T·∫ÆC CHUNG CHO M·ªåI PROMPT:
- ·∫¢nh ph·∫£i tr√¥ng nh∆∞ CH·ª§P TH·∫¨T, kh√¥ng gi·ªëng AI t·∫°o
- Kh√¥ng th√™m text, watermark, logo
- Keyword b·∫Øt bu·ªôc cu·ªëi prompt: 'photorealistic, shot on DSLR, natural lighting, real estate photography, 8k, sharp focus'

CH·ªà TR·∫¢ V·ªÄ PROMPT CU·ªêI C√ôNG (b∆∞·ªõc 3). Kh√¥ng gi·∫£i th√≠ch, kh√¥ng ƒë√°nh s·ªë b∆∞·ªõc.`;

    try {
        const startTime = Date.now();
        const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${geminiKey}`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                contents: [{
                    parts: [
                        { text: visionPrompt },
                        {
                            inline_data: {
                                mime_type: "image/jpeg",
                                data: cleanBase64
                            }
                        }
                    ]
                }]
            })
        });

        const data = await response.json();

        // Log token usage
        if (data.usageMetadata) {
            console.log('[AI] Token Usage (Analyze):', data.usageMetadata);
        }

        await saveApiLog({
            provider: 'gemini',
            model: 'gemini-2.0-flash',
            endpoint: 'analyzeImage',
            status_code: response.status,
            duration_ms: Date.now() - startTime,
            prompt_preview: 'Vision Analysis: Pain-point detection (Balanced Mode)'
        });

        if (response.ok && data.candidates?.[0]?.content?.parts?.[0]?.text) {
            return data.candidates[0].content.parts[0].text;
        } else {
            console.error('Gemini Vision Error:', data);
            return null;
        }

    } catch (error) {
        console.error('Gemini Vision Fetch Error:', error);
        return null;
    }
}

/**
 * Phase 2: Image-to-Image Enhancement
 * Sends original image + fix prompt to Gemini Flash for editing while preserving structure.
 * Falls back to Imagen 4 text-to-image if Gemini Flash img editing fails.
 */
export async function enhanceImageWithAI(
    base64Image: string,
    fixPrompt: string,
    onStatusUpdate?: (status: string) => void
): Promise<string | null> {
    const geminiKey = await getApiKey('gemini');
    if (!geminiKey) return null;

    const cleanBase64 = base64Image.replace(/^data:image\/(png|jpeg|webp);base64,/, '');

    // Phase 2: Marketing-aware enhancement with photorealism emphasis
    const editInstruction = `You are a professional real estate photo editor. Edit this photo based on these improvements: "${fixPrompt}".

    CRITICAL: The result MUST look like a REAL PHOTOGRAPH taken by a DSLR camera, NOT like AI-generated art.
    
    RULES:
    1. KEEP the lot boundaries, curbs, roads, and building structures visible and intact.
    2. FOLLOW the fix prompt instructions precisely ‚Äî add elements it describes (houses, roads, grass, furniture, etc.).
    3. PHOTOREALISM: Use natural film grain, realistic lens depth of field, and consistent shadow direction. No plastic/glossy look.
    4. LIGHTING: Golden hour or clear daylight. Shadows must be soft and directional.
    5. SCALE: Any added elements (houses, trees, people) must be proportionally correct.
    
    Negative prompt: cartoon, painting, 3d render, plastic texture, oversaturated, neon, fantasy, watermark, text overlay.`;

    // Strategy 1: Gemini 2.0 Flash Image Generation (supports img2img via generateContent)
    onStatusUpdate?.('üé® ƒêang ph·ªß xanh kh√¥ng gian...');
    try {
        const gStartTime = Date.now();
        console.log('[AI Enhance] Trying Gemini Flash image editing (img2img/Balanced)...');

        const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp-image-generation:generateContent?key=${geminiKey}`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                contents: [{
                    parts: [
                        { text: editInstruction },
                        {
                            inline_data: {
                                mime_type: 'image/jpeg',
                                data: cleanBase64
                            }
                        }
                    ]
                }],
                generationConfig: {
                    responseModalities: ['IMAGE', 'TEXT']
                }
            })
        });

        const data = await response.json();

        // Log token usage
        if (data.usageMetadata) {
            console.log('[AI] Token Usage (Enhance):', data.usageMetadata);
        }

        await saveApiLog({
            provider: 'gemini',
            model: 'gemini-2.0-flash-exp-image-generation',
            endpoint: 'enhanceImage',
            status_code: response.status,
            duration_ms: Date.now() - gStartTime,
            prompt_preview: 'Image-to-Image Enhancement (Balanced Mode)'
        });

        if (response.ok && data.candidates?.[0]?.content?.parts) {
            const parts = data.candidates[0].content.parts;
            const imagePart = parts.find((p: any) => p.inline_data && p.inline_data.mime_type.startsWith('image/'));

            if (imagePart) {
                console.log('[AI Enhance] ‚úÖ Gemini Flash image editing successful!');
                return `data:${imagePart.inline_data.mime_type};base64,${imagePart.inline_data.data}`;
            }
        }

        console.error('[AI Enhance] Gemini Flash Image Gen failed:', JSON.stringify(data).substring(0, 500));
        // Fallthrough to return null - DO NOT use text-to-image fallback for Enhance mode
        // as it creates a completely new image that ignores the original structure.
        return null;

    } catch (error) {
        console.error('[AI Enhance] Strategy 1 Error:', error);
        return null;
    }

    /*
    // DISABLE FALLBACK TO TEXT-TO-IMAGE FOR ENHANCE MODE
    // because it hallucinates new structures instead of preserving original
     
    // Strategy 2: Fallback to Imagen 4 text-to-image (no img2img, but with detailed prompt)
    onStatusUpdate?.('‚ú® ƒêang ho√†n thi·ªán kh√¥ng gian s·ªëng...');
    console.log('[AI Enhance] Falling back to Imagen 4 text-to-image...');
    
    const imagenModels = [
        'imagen-4.0-generate-001',
        'imagen-4.0-fast-generate-001',
    ];
    
    for (const modelId of imagenModels) {
        try {
            const iStartTime = Date.now();
            console.log(`[AI Enhance] Trying ${modelId}...`);
    
            const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/${modelId}:predict`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'x-goog-api-key': geminiKey
                },
                body: JSON.stringify({
                    instances: [{ prompt: fixPrompt }],
                    parameters: { sampleCount: 1 }
                })
            });
    
            const data = await response.json();
    
            await saveApiLog({
                provider: 'gemini',
                model: modelId,
                endpoint: 'enhanceImage-fallback',
                status_code: response.status,
                duration_ms: Date.now() - iStartTime,
                prompt_preview: fixPrompt.substring(0, 100)
            });
    
            if (response.ok && data.predictions?.[0]?.bytesBase64Encoded) {
                console.log(`[AI Enhance] ‚úÖ ${modelId} fallback successful!`);
                return `data:image/png;base64,${data.predictions[0].bytesBase64Encoded}`;
            } else {
                console.warn(`[AI Enhance] ${modelId} failed:`, data.error?.message || '');
            }
        } catch (err) {
            console.error(`[AI Enhance] ${modelId} catch:`, err);
        }
    }
    
    // Strategy 3: Final fallback to existing generateImageWithAI
    console.log('[AI Enhance] All img2img strategies failed. Using text-to-image fallback...');
    return generateImageWithAI(fixPrompt);
    */
}

export async function generateImageWithAI(prompt: string): Promise<string | null> {
    const startTime = Date.now();
    // 1. Try Stability AI
    const stabilityKey = await getApiKey('stability');

    if (stabilityKey) {
        try {
            console.log('Trying Stability AI...');
            const response = await fetch('https://api.stability.ai/v1/generation/stable-diffusion-xl-1024-v1-0/text-to-image', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Accept': 'application/json',
                    'Authorization': `Bearer ${stabilityKey}`
                },
                body: JSON.stringify({
                    text_prompts: [{ text: prompt }],
                    cfg_scale: 7,
                    height: 1024,
                    width: 1024,
                    steps: 30,
                    samples: 1,
                })
            });

            const data = await response.json();

            await saveApiLog({
                provider: 'stability',
                model: 'sdxl-1.0',
                endpoint: 'text-to-image',
                status_code: response.status,
                duration_ms: Date.now() - startTime,
                prompt_preview: prompt.substring(0, 100)
            });

            if (response.ok && data.artifacts && data.artifacts.length > 0) {
                return `data:image/png;base64,${data.artifacts[0].base64}`;
            }
        } catch (err) {
            console.error('Stability API Error:', err);
        }
    }

    // 2. Try Google Imagen (via Gemini API Key)
    const geminiKey = await getApiKey('gemini');
    if (geminiKey) {
        const enhancedPrompt = `High-end real estate photography: ${prompt}, hyper-realistic, 8k resolution, architectural lighting, sharp focus, clean composition, absolutely NO text, NO letters, NO watermark, NO labels, NO signs`;

        // Imagen 4.0 models (Imagen 3 has been shut down by Google)
        const imagenModels = [
            'imagen-4.0-generate-001',
            'imagen-4.0-fast-generate-001',
            'imagen-4.0-ultra-generate-001',
        ];

        for (const modelId of imagenModels) {
            try {
                const iStartTime = Date.now();
                console.log(`[AI] Trying Google ${modelId}...`);

                // CRITICAL: Google Imagen requires x-goog-api-key header, NOT ?key= query param
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/${modelId}:predict`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'x-goog-api-key': geminiKey
                    },
                    body: JSON.stringify({
                        instances: [{ prompt: enhancedPrompt }],
                        parameters: {
                            sampleCount: 1
                        }
                    })
                });

                const data = await response.json();

                await saveApiLog({
                    provider: 'gemini',
                    model: modelId,
                    endpoint: 'predict',
                    status_code: response.status,
                    duration_ms: Date.now() - iStartTime,
                    prompt_preview: prompt.substring(0, 100)
                });

                if (response.ok && data.predictions && data.predictions.length > 0) {
                    const prediction = data.predictions[0];
                    const base64Data = prediction.bytesBase64Encoded;

                    if (base64Data) {
                        console.log(`[AI] ‚úÖ Image generated with ${modelId}!`);
                        return `data:image/png;base64,${base64Data}`;
                    }
                } else {
                    console.warn(`[AI] ‚ùå ${modelId} failed (${response.status}):`, data.error?.message || JSON.stringify(data).substring(0, 200));
                }
            } catch (err) {
                console.error(`[AI] ${modelId} catch:`, err);
            }
        }

        // Fallback 2B: Gemini 2.0 Flash (FREE - supports image generation via generateContent)
        console.log('[AI] Imagen requires billing. Trying Gemini 2.0 Flash (free) as fallback...');
        try {
            const gStartTime = Date.now();
            const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp-image-generation:generateContent?key=${geminiKey}`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    contents: [{ parts: [{ text: enhancedPrompt }] }],
                    generationConfig: {
                        responseModalities: ["IMAGE", "TEXT"]
                    }
                })
            });

            const data = await response.json();

            await saveApiLog({
                provider: 'gemini',
                model: 'gemini-2.0-flash-exp-image-generation',
                endpoint: 'generateContent',
                status_code: response.status,
                duration_ms: Date.now() - gStartTime,
                prompt_preview: prompt.substring(0, 100)
            });

            if (response.ok && data.candidates?.[0]?.content?.parts) {
                for (const part of data.candidates[0].content.parts) {
                    if (part.inlineData?.data) {
                        const mimeType = part.inlineData.mimeType || 'image/png';
                        console.log('[AI] ‚úÖ Gemini Flash generated image successfully!');
                        return `data:${mimeType};base64,${part.inlineData.data}`;
                    }
                }
            } else {
                console.warn('[AI] Gemini Flash Image failed:', data.error?.message || JSON.stringify(data).substring(0, 200));
            }
        } catch (err) {
            console.error('[AI] Gemini Flash catch:', err);
        }
    }

    // 3. Try OpenAI DALL-E 3
    const openaiKey = await getApiKey('openai');
    if (openaiKey) {
        const dStartTime = Date.now();
        try {
            console.log('Trying OpenAI DALL-E 3...');
            const response = await fetch('https://api.openai.com/v1/images/generations', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${openaiKey}`
                },
                body: JSON.stringify({
                    model: "dall-e-3",
                    prompt: prompt,
                    n: 1,
                    size: "1024x1024",
                })
            });

            const data = await response.json();

            await saveApiLog({
                provider: 'openai',
                model: 'dall-e-3',
                endpoint: 'generations',
                status_code: response.status,
                duration_ms: Date.now() - dStartTime,
                prompt_preview: prompt.substring(0, 100)
            });

            if (response.ok && data.data && data.data.length > 0) {
                return data.data[0].url;
            }
        } catch (err) {
            console.error('OpenAI DALL-E catch:', err);
        }
    }

    throw new Error('Kh√¥ng c√≥ API n√†o t·∫°o ƒë∆∞·ª£c ·∫£nh. Vui l√≤ng ki·ªÉm tra API Key trong Admin.');
}
